{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "TUE_5LSM0_g6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vorst4/TUE_5LSM0_g6/blob/master/TUE_5LSM0_g6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGfJwDKxMQEw",
        "colab_type": "code",
        "outputId": "66fadd2e-d91f-4f36-f6ec-2cf4b383c0b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "# ------------------------------ Import modules ------------------------------ #\n",
        "\n",
        "import os\n",
        "import json\n",
        "import importlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "from glob import glob\n",
        "from datetime import datetime\n",
        "from PIL import Image\n",
        "from google.colab import drive\n",
        "\n",
        "try:\n",
        "  from efficientnet_pytorch import EfficientNet\n",
        "except:\n",
        "  !pip install efficientnet_pytorch\n",
        "  from efficientnet_pytorch import EfficientNet\n",
        "\n",
        "try:\n",
        "  import shap\n",
        "except:\n",
        "  !pip install shap\n",
        "  import shap\n",
        "\n",
        "\n",
        "# ----------------------------- Initialize Colab ----------------------------- #\n",
        "#\n",
        "# NOTE: all console commands (the ones that start with !) cannot be run from a \n",
        "# .py script. Usually this is possible using the command 'os.system('...')'.\n",
        "# However, in Colab, it is for some reason not possible to obtain the console\n",
        "# output of the command that is run. This makes it impossible to notify the user\n",
        "# if an error occurs. All the commands therefore need to be run in the main\n",
        "# .ipynb script (which is this script).\n",
        "#\n",
        "\n",
        "\n",
        "# check if GPU is enabled\n",
        "if torch.cuda.is_available() == False:\n",
        "  print('\\nWARNING: GPU not enabled. Goto runtime -> change runtime type')\n",
        "\n",
        "\n",
        "# mount Google Drive (if needed)\n",
        "if not os.path.exists('drive'):\n",
        "  print('\\nMounting Google Drive...')\n",
        "  drive.mount('/content/drive')\n",
        "  print('Done')\n",
        "\n",
        "\n",
        "# setup Git (if needed)\n",
        "if not os.path.exists('TUE_5LSM0_g6'):\n",
        "  print('\\nSetting up git...')\n",
        "  print('...Loading github.json from Google Drive')\n",
        "  with open('/content/drive/My Drive/github.json', 'r') as json_file:\n",
        "    gitconfig = json.load(json_file)\n",
        "  print('...Cloning git repo')\n",
        "  url = 'https://'+gitconfig[\"username\"]+':'+gitconfig[\"key\"]+\\\n",
        "        '@github.com/vorst4/TUE_5LSM0_g6.git'\n",
        "  !git clone {url}\n",
        "  print('...Setting username and email')\n",
        "  !git -C TUE_5LSM0_g6 config user.name {gitconfig[\"username\"]}\n",
        "  !git -C TUE_5LSM0_g6 config user.email {gitconfig[\"email\"]}\n",
        "  print('Done')\n",
        "\n",
        "\n",
        "# remove default sample_data folder (if needed)\n",
        "if os.path.exists('sample_data'):\n",
        "  print('\\nRemoving sample_data...')\n",
        "  os.system('rm -r sample_data')\n",
        "  print('Done')\n",
        "\n",
        "\n",
        "# copy and unzip data from Google Drive (if needed)\n",
        "if not os.path.exists('ISIC_2019_Test_Input'):\n",
        "  print('\\nGetting data...')\n",
        "  print('...Copying data.zip from Google Drive to workfolder')\n",
        "  !cp 'drive/My Drive/5LSM0-final-assignment/data.zip' .\n",
        "  print('...Unpacking data.zip')\n",
        "  !unzip -q data.zip\n",
        "  print('...Removing data.zip')\n",
        "  !rm data.zip\n",
        "  print('Done\\n')\n",
        "\n",
        "\n",
        "# ----------------------------- Import Functions ----------------------------- #\n",
        "#\n",
        "# NOTE: The modules need to be forcibly reloaded because Colab does not do this\n",
        "# by default, even if the module has changed.\n",
        "#\n",
        "\n",
        "# dataloaders\n",
        "import TUE_5LSM0_g6.dataloaders\n",
        "importlib.reload(TUE_5LSM0_g6.dataloaders)\n",
        "dataloaders = TUE_5LSM0_g6.dataloaders.dataloaders\n",
        "\n",
        "# train & accuracy\n",
        "import TUE_5LSM0_g6.train\n",
        "importlib.reload(TUE_5LSM0_g6.train)\n",
        "train = TUE_5LSM0_g6.train.train\n",
        "accuracy = TUE_5LSM0_g6.train.accuracy\n",
        "\n",
        "# resnet18\n",
        "import TUE_5LSM0_g6.resnet18\n",
        "importlib.reload(TUE_5LSM0_g6.resnet18)\n",
        "resnet18 = TUE_5LSM0_g6.resnet18.resnet18\n",
        "\n",
        "\n",
        "# --------------------------------- Settings --------------------------------- #\n",
        "\n",
        "# settings object\n",
        "S = type('settings', (), {})()\n",
        "\n",
        "# use gpu/cpu\n",
        "if torch.cuda.is_available():\n",
        "  S.device = torch.device('cuda')\n",
        "else:\n",
        "  S.device = torch.device('cpu')\n",
        "\n",
        "# image size (squared)\n",
        "S.img_size = 256\n",
        "\n",
        "# set variable type\n",
        "S.dtype = torch.float32\n",
        "\n",
        "# when to print\n",
        "S.print_every = 10\n",
        "\n",
        "# number of epochs to run\n",
        "S.epochs = 10\n",
        "\n",
        "# batch size, increase this until the RAM is full\n",
        "S.batch_size = 1\n",
        "\n",
        "# percentage of original train set that is to be used for validation\n",
        "S.val_ratio = 0.1\n",
        "\n",
        "# restore last backup of model?\n",
        "S.load_backup = False\n",
        "\n",
        "# Create backup each epoch?\n",
        "S.backup_each_epoch = True\n",
        "\n",
        "# Create backup if training is finished?\n",
        "S.backup_on_finish = False\n",
        "\n",
        "\n",
        "# ----------------------------------- Main ----------------------------------- #\n",
        "\n",
        "# create data loader objects for train, validation and test set.\n",
        "dl_train, dl_val, dl_test = dataloaders(batch_size=S.batch_size,\n",
        "                                        val_ratio = S.val_ratio,\n",
        "                                        img_size = S.img_size)\n",
        "\n",
        "# learning rate (with decay)\n",
        "# todo: make a script that runs the model with different rates\n",
        "learning_rate = 1e-3\n",
        "decayRate = 0.99\n",
        "\n",
        "# model\n",
        "# model = resnet18(S.img_size)\n",
        "model = EfficientNet.from_name('efficientnet-b0')\n",
        "\n",
        "# print layer sizes\n",
        "model.print_layer_sizes()\n",
        "\n",
        "asdf()\n",
        "\n",
        "# load backup\n",
        "if S.load_backup:\n",
        "  model.restore_latest()\n",
        "\n",
        "# optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# learning rate\n",
        "lr_exp = optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=decayRate)\n",
        "\n",
        "# train\n",
        "train(model, optimizer, dl_train, dl_val, lr_exp, S)\n",
        "\n",
        "# visualize results\n",
        "model.visualize()\n",
        "\n",
        "# save obtained model (not needed if it is already saved after each epoch)\n",
        "if S.backup_on_finish and not S.backup_each_epoch:\n",
        "  model.backup_to_drive()\n",
        "\n",
        "# get accuracy best model\n",
        "best_model = model\n",
        "accuracy(dl_test, best_model)\n",
        "\n",
        "# create csv file of test data\n",
        "make_csv(best_model)\n",
        "\n",
        "\n",
        "# ----------------------------------- End ------------------------------------ #\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting efficientnet_pytorch\n",
            "  Downloading https://files.pythonhosted.org/packages/b8/cb/0309a6e3d404862ae4bc017f89645cf150ac94c14c88ef81d215c8e52925/efficientnet_pytorch-0.6.3.tar.gz\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from efficientnet_pytorch) (1.4.0)\n",
            "Building wheels for collected packages: efficientnet-pytorch\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.6.3-cp36-none-any.whl size=12422 sha256=729b17cdd2e2551ba34bb126c4a12d344c99e0e23429eee0356e289e2bac9621\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/1e/a9/2a578ba9ad04e776e80bf0f70d8a7f4c29ec0718b92d8f6ccd\n",
            "Successfully built efficientnet-pytorch\n",
            "Installing collected packages: efficientnet-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.6.3\n",
            "Collecting shap\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/77/b504e43e21a2ba543a1ac4696718beb500cfa708af2fb57cb54ce299045c/shap-0.35.0.tar.gz (273kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 4.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from shap) (1.18.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from shap) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from shap) (0.22.2.post1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from shap) (1.0.3)\n",
            "Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.6/dist-packages (from shap) (4.38.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->shap) (0.14.1)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->shap) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->shap) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas->shap) (1.12.0)\n",
            "Building wheels for collected packages: shap\n",
            "  Building wheel for shap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for shap: filename=shap-0.35.0-cp36-cp36m-linux_x86_64.whl size=394128 sha256=cf146215de1b94d7a4fb2b33d5b99549fdfea9757753229cabd860c376a56857\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f7/0f/b57055080cf8894906b3bd3616d2fc2bfd0b12d5161bcb24ac\n",
            "Successfully built shap\n",
            "Installing collected packages: shap\n",
            "Successfully installed shap-0.35.0\n",
            "\n",
            "Mounting Google Drive...\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "Done\n",
            "\n",
            "Setting up git...\n",
            "...Loading github.json from Google Drive\n",
            "...Cloning git repo\n",
            "Cloning into 'TUE_5LSM0_g6'...\n",
            "remote: Enumerating objects: 16, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 247 (delta 7), reused 7 (delta 3), pack-reused 231\u001b[K\n",
            "Receiving objects: 100% (247/247), 306.98 KiB | 13.95 MiB/s, done.\n",
            "Resolving deltas: 100% (130/130), done.\n",
            "...Setting username and email\n",
            "Done\n",
            "\n",
            "Removing sample_data...\n",
            "Done\n",
            "\n",
            "Getting data...\n",
            "...Copying data.zip from Google Drive to workfolder\n",
            "...Unpacking data.zip\n",
            "...Removing data.zip\n",
            "Done\n",
            "\n",
            "\n",
            "Below are the output sizes of each layer (input img: 256x256)\n",
            "  conv1   torch.Size([1, 64, 86, 86])\n",
            "  layer1  torch.Size([1, 64, 43, 43])\n",
            "  layer2  torch.Size([1, 128, 22, 22])\n",
            "  layer3  torch.Size([1, 256, 11, 11])\n",
            "  layer4  torch.Size([1, 512, 6, 6])\n",
            "  pool    torch.Size([1, 512, 1, 1])\n",
            "  dense   torch.Size([1, 9])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-bdac42d5976a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_layer_sizes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m \u001b[0masdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;31m# load backup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'asdf' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rkbwum3UmL6w",
        "colab_type": "code",
        "outputId": "8e47e153-c04f-45b7-b554-1b35f1806e20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        }
      },
      "source": [
        "# ------------------------- GIT Pull, Commit & Push -------------------------- #\n",
        "\n",
        "def git():\n",
        "\n",
        "  if not input('\\nPull? (y)') == 'y':\n",
        "    return\n",
        "  !git -C /content/TUE_5LSM0_g6 pull\n",
        "\n",
        "  commit_msg = '\\''+input('\\nEnter commit message: ')+'\\''\n",
        "\n",
        "  if not input('\\nCommit? (y)') == 'y':\n",
        "    return\n",
        "  !git -C /content/TUE_5LSM0_g6 add .\n",
        "  !git -C /content/TUE_5LSM0_g6 commit -m {commit_msg}\n",
        "\n",
        "  if not input('\\nPush? (y)') == 'y':\n",
        "    return\n",
        "  !git -C /content/TUE_5LSM0_g6 push\n",
        "\n",
        "git()\n",
        "\n",
        "# ----------------------------------- End ------------------------------------ #\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Pull? (y)y\n",
            "Already up to date.\n",
            "\n",
            "Enter commit message: fixed resnet such that the dense layer has size 1x1. Also added method print_layer_sizes\n",
            "\n",
            "Commit? (y)y\n",
            "[master 940a9ae] fixed resnet such that the dense layer has size 1x1. Also added method print_layer_sizes\n",
            " 1 file changed, 49 insertions(+), 8 deletions(-)\n",
            "\n",
            "Push? (y)y\n",
            "Counting objects: 3, done.\n",
            "Delta compression using up to 2 threads.\n",
            "Compressing objects: 100% (3/3), done.\n",
            "Writing objects: 100% (3/3), 885 bytes | 885.00 KiB/s, done.\n",
            "Total 3 (delta 2), reused 0 (delta 0)\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/vorst4/TUE_5LSM0_g6.git\n",
            "   fecb673..940a9ae  master -> master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFe1qFwU_Adt",
        "colab_type": "code",
        "outputId": "c42bdea7-1894-41a5-c4b4-f417ce65f63d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "np.empty(3)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.26e-321, 6.42e-323, 4.30e-322])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    }
  ]
}