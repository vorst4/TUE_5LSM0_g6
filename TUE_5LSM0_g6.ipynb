{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "TUE_5LSM0_g6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vorst4/TUE_5LSM0_g6/blob/master/TUE_5LSM0_g6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGfJwDKxMQEw",
        "colab_type": "code",
        "outputId": "ce52bd14-6883-4cb4-f501-d4dfa9da4806",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        }
      },
      "source": [
        "\n",
        "# ------------------------------ Import modules ------------------------------ #\n",
        "\n",
        "import os\n",
        "import json\n",
        "import importlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "from glob import glob\n",
        "from datetime import datetime\n",
        "from PIL import Image\n",
        "from google.colab import drive\n",
        "\n",
        "try:\n",
        "  import shap\n",
        "except:\n",
        "  !pip install shap\n",
        "  import shap\n",
        "\n",
        "\n",
        "# ----------------------------- Initialize Colab ----------------------------- #\n",
        "#\n",
        "# NOTE: all console commands (the ones that start with !) cannot be run from a \n",
        "# .py script. Usually this is possible using the command 'os.system('...')'.\n",
        "# However, in Colab, it is for some reason not possible to obtain the console\n",
        "# output of the command that is run. This makes it impossible to notify the user\n",
        "# if an error occurs. All the commands therefore need to be run in the main\n",
        "# .ipynb script (which is this script).\n",
        "#\n",
        "\n",
        "# mount Google Drive (if needed)\n",
        "if not os.path.exists('drive'):\n",
        "  print('\\nMounting Google Drive...')\n",
        "  drive.mount('/content/drive')\n",
        "  print('Done')\n",
        "\n",
        "\n",
        "# setup Git (if needed)\n",
        "if not os.path.exists('TUE_5LSM0_g6'):\n",
        "  print('\\nSetting up git...')\n",
        "  print('...Loading github.json from Google Drive')\n",
        "  with open('/content/drive/My Drive/github.json', 'r') as json_file:\n",
        "    gitconfig = json.load(json_file)\n",
        "  print('...Cloning git repo')\n",
        "  url = 'https://'+gitconfig[\"username\"]+':'+gitconfig[\"key\"]+\\\n",
        "        '@github.com/vorst4/TUE_5LSM0_g6.git'\n",
        "  !git clone {url}\n",
        "  print('...Setting username and email')\n",
        "  !git -C TUE_5LSM0_g6 config user.name {gitconfig[\"username\"]}\n",
        "  !git -C TUE_5LSM0_g6 config user.email {gitconfig[\"email\"]}\n",
        "  print('Done')\n",
        "\n",
        "\n",
        "# check if GPU is enabled\n",
        "if torch.cuda.is_available() == False:\n",
        "  raise ValueError('GPU not enabled. Goto runtime -> change runtime type')\n",
        "\n",
        "\n",
        "# remove default sample_data folder (if needed)\n",
        "if os.path.exists('sample_data'):\n",
        "  print('\\nRemoving sample_data...')\n",
        "  os.system('rm -r sample_data')\n",
        "  print('Done')\n",
        "\n",
        "\n",
        "# copy and unzip data from Google Drive (if needed)\n",
        "if not os.path.exists('ISIC_2019_Test_Input'):\n",
        "  print('\\nGetting data...')\n",
        "  print('...Copying data.zip from Google Drive to workfolder')\n",
        "  !cp 'drive/My Drive/5LSM0-final-assignment/data.zip' .\n",
        "  print('...Unpacking data.zip')\n",
        "  !unzip -q data.zip\n",
        "  print('...Removing data.zip')\n",
        "  !rm data.zip\n",
        "  print('Done\\n')\n",
        "\n",
        "\n",
        "# ----------------------------- Import Functions ----------------------------- #\n",
        "#\n",
        "# NOTE: The modules need to be forcibly reloaded because Colab does not do this\n",
        "# by default, even if the module has changed.\n",
        "#\n",
        "\n",
        "# dataloaders\n",
        "import TUE_5LSM0_g6.dataloaders\n",
        "importlib.reload(TUE_5LSM0_g6.dataloaders)\n",
        "dataloaders = TUE_5LSM0_g6.dataloaders.dataloaders\n",
        "\n",
        "# train & accuracy\n",
        "import TUE_5LSM0_g6.train\n",
        "importlib.reload(TUE_5LSM0_g6.train)\n",
        "train = TUE_5LSM0_g6.train.train\n",
        "accuracy = TUE_5LSM0_g6.train.accuracy\n",
        "\n",
        "# resnet18\n",
        "import TUE_5LSM0_g6.resnet18\n",
        "importlib.reload(TUE_5LSM0_g6.resnet18)\n",
        "resnet18 = TUE_5LSM0_g6.resnet18.resnet18\n",
        "\n",
        "\n",
        "# --------------------------------- Settings --------------------------------- #\n",
        "\n",
        "# settings object\n",
        "S = type('settings', (), {})()\n",
        "\n",
        "# use gpu\n",
        "S.device = torch.device('cuda')\n",
        "\n",
        "# image size (squared)\n",
        "S.img_size = 256\n",
        "\n",
        "# set variable type\n",
        "S.dtype = torch.float32\n",
        "\n",
        "# when to print\n",
        "S.print_every = 500\n",
        "\n",
        "# number of epochs to run\n",
        "S.epochs = 10\n",
        "\n",
        "# batch size, increase this until the RAM is full\n",
        "S.batch_size = 16\n",
        "\n",
        "# percentage of original train set that is to be used for validation\n",
        "S.val_ratio = 10\n",
        "\n",
        "# restore last backup of model?\n",
        "S.load_backup = False\n",
        "\n",
        "# Create backup each epoch?\n",
        "S.backup_each_epoch = True\n",
        "\n",
        "# Create backup if training is finished?\n",
        "S.backup_on_finish = False\n",
        "\n",
        "\n",
        "# ----------------------------------- Main ----------------------------------- #\n",
        "\n",
        "# create data loader objects for train, validation and test set.\n",
        "dl_train, dl_val, dl_test = dataloaders(batch_size=S.batch_size,\n",
        "                                        val_ratio = S.val_ratio,\n",
        "                                        img_size = S.img_size)\n",
        "\n",
        "# learning rate (with decay)\n",
        "# todo: make a script that runs the model with different rates\n",
        "learning_rate = 1e-3\n",
        "decayRate = 0.99\n",
        "\n",
        "# model\n",
        "model = resnet18(S.img_size)\n",
        "\n",
        "# load backup\n",
        "if S.load_backup:\n",
        "  model.restore_latest()\n",
        "\n",
        "# optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# learning rate\n",
        "lr_exp = optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=decayRate)\n",
        "\n",
        "# train\n",
        "train(model, optimizer, dl_train, dl_val, lr_exp, S)\n",
        "\n",
        "# visualize results\n",
        "model.visualize()\n",
        "\n",
        "# save obtained model (not needed if it is already saved after each epoch)\n",
        "if S.backup_on_finish and not S.backup_each_epoch:\n",
        "  model.backup_to_drive()\n",
        "\n",
        "# get accuracy best model\n",
        "best_model = model\n",
        "accuracy(dl_test, best_model)\n",
        "\n",
        "# create csv file of test data\n",
        "make_csv(best_model)\n",
        "\n",
        "\n",
        "# ----------------------------------- End ------------------------------------ #\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/10, iter 0/1583, t_elap.00h00m00s  t_rem.04h11m10s, loss 2.6230 acc 39.22% (993/2532)\n",
            "\tak       0/87       bcc      0/332      bkl     61/262      df       0/24       \n",
            "\tmel      0/452      nv     932/1287     scc      0/63       vasc     0/25        \n",
            "Epoch 0/10, iter 100/1583, t_elap.00h04m47s  t_rem.12h26m47s, loss 1.7059 acc 51.03% (1292/2532)\n",
            "\tak       0/87       bcc     36/332      bkl      1/262      df       0/24       \n",
            "\tmel     16/452      nv    1236/1287     scc      3/63       vasc     0/25        \n",
            "Epoch 0/10, iter 200/1583, t_elap.00h09m37s  t_rem.12h28m00s, loss 1.7530 acc 54.19% (1372/2532)\n",
            "\tak       0/87       bcc    118/332      bkl      0/262      df       0/24       \n",
            "\tmel    134/452      nv    1120/1287     scc      0/63       vasc     0/25        \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rkbwum3UmL6w",
        "colab_type": "code",
        "outputId": "bde2b545-ad08-4034-fbd4-51b5f7bf9a62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        }
      },
      "source": [
        "# ------------------------- GIT Pull, Commit & Push -------------------------- #\n",
        "\n",
        "def git():\n",
        "\n",
        "  if not input('\\nPull? (y)') == 'y':\n",
        "    return\n",
        "  !git -C /content/TUE_5LSM0_g6 pull\n",
        "\n",
        "  commit_msg = '\\''+input('\\nEnter commit message: ')+'\\''\n",
        "\n",
        "  if not input('\\nCommit? (y)') == 'y':\n",
        "    return\n",
        "  !git -C /content/TUE_5LSM0_g6 add .\n",
        "  !git -C /content/TUE_5LSM0_g6 commit -m {commit_msg}\n",
        "\n",
        "  if not input('\\nPush? (y)') == 'y':\n",
        "    return\n",
        "  !git -C /content/TUE_5LSM0_g6 push\n",
        "\n",
        "git()\n",
        "\n",
        "# ----------------------------------- End ------------------------------------ #\n"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Pull? (y)y\n",
            "Already up to date.\n",
            "\n",
            "Enter commit message: -\n",
            "\n",
            "Commit? (y)y\n",
            "On branch master\n",
            "Your branch is up to date with 'origin/master'.\n",
            "\n",
            "nothing to commit, working tree clean\n",
            "\n",
            "Push? (y)y\n",
            "Everything up-to-date\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFe1qFwU_Adt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c42bdea7-1894-41a5-c4b4-f417ce65f63d"
      },
      "source": [
        "np.empty(3)\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.26e-321, 6.42e-323, 4.30e-322])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    }
  ]
}