{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "TUE-5LSM0-g6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vorst4/temp_repos/blob/master/TUE_5LSM0_g6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGfJwDKxMQEw",
        "colab_type": "code",
        "outputId": "3c758471-d14f-4e93-dcac-f10faa878e58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# ------------------------------ Import modules ------------------------------ #\n",
        "\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "from google.colab import drive\n",
        "from glob import glob\n",
        "from datetime import datetime\n",
        "\n",
        "# --------------------------- Functions & Classes ---------------------------- #\n",
        "\n",
        "def download_and_organize(force=False, \n",
        "                          mnt_path='/content/drive', \n",
        "                          token_path='/'):\n",
        "  \"\"\"\n",
        "  This function donwloads and organizes the data. More specifically:\n",
        "  1.  It checks if the folder 'ISIC_2019_Training_Input' exsists. If this is \n",
        "      the case, the function will assume that the data is already downloaded \n",
        "      and organized and no further action will be taken. If for some reason the\n",
        "      function needs to be executed anyway, it can be forced (force=True).\n",
        "  2.  Download the ISIC 2019 data from Kaggle. Your Kaggle token is needed for \n",
        "      this. To download your Kaggle token, visit https://www.kaggle.com , then \n",
        "      go to 'my account' and then 'download API token'. To pass your Kaggle\n",
        "      token to the script, Google Drive is used. This way, multiple people can\n",
        "      run/share the same script without sharing sensitive data. The token \n",
        "      should have the name 'kaggle.json' and be placed in Google Drive at the\n",
        "      path specified by 'token_path'.\n",
        "  3.  The downloaded data is unziped.\n",
        "  4.  The train data/images are organized into subfolders. Each image is placed \n",
        "      into a subfolder that corresponds to its class. Doing this makes it\n",
        "      possible to use 'torchvision.datasets.ImageFolder'.\n",
        "  5.  The zip files and csv files are deleted since they are not needed anymore.\n",
        "\n",
        "  Note: currently the metadata ignored, meaning it is not linked to the image.   \n",
        "  \n",
        "  Args:\n",
        "    force (bool): force to run the function, even if the data is already \n",
        "      downloaded and organized\n",
        "    mnt_path (string): path where the google drive will be mounted.\n",
        "    token_path (string): Path on Google Drive where the token can be found.\n",
        "      With '/' being the root of Google Drive.\n",
        "\n",
        "  Returns:\n",
        "    (none)\n",
        "  \"\"\"\n",
        "\n",
        "  # do not download if it already exists\n",
        "  if os.path.exists('ISIC_2019_Training_Input') and force == False:\n",
        "    return\n",
        "\n",
        "  # mount google drive\n",
        "  print('\\nMounting Google Drive...')\n",
        "  drive.mount(mnt_path, force_remount=True)\n",
        "  print('...Done')\n",
        "\n",
        "  # Set kaggle configuration directory\n",
        "  os.environ['KAGGLE_CONFIG_DIR'] = mnt_path+'/My Drive'+token_path\n",
        "\n",
        "  # download data\n",
        "  print('\\nDownloading...')\n",
        "  !kaggle datasets download -d kioriaanthony/isic-2019-training-input\n",
        "  !kaggle datasets download -d kioriaanthony/isic-2019-training-groundtruth\n",
        "  !kaggle datasets download -d kioriaanthony/isic-2019-test-input\n",
        "  # !kaggle datasets download -d kioriaanthony/isic-2019-training-metadata\n",
        "  # !kaggle datasets download -d kioriaanthony/isic-2019-test-metadata\n",
        "  print('...Done')\n",
        "\n",
        "  # unzip it (quietly)\n",
        "  print('\\nUnzipping...')\n",
        "  !unzip -q isic-2019-training-input.zip\n",
        "  !unzip -q isic-2019-training-groundtruth.zip\n",
        "  !unzip -q isic-2019-test-input\n",
        "  # !unzip -q isic-2019-test-metadata.zip\n",
        "  # !unzip -q isic-2019-training-metadata.zip\n",
        "  print('...Done')\n",
        "\n",
        "  # resize and zero-padd images to desired size\n",
        "  desired_size = 256\n",
        "  print('\\nResizing and padding images...')\n",
        "  for path in glob('/content/ISIC_2019_Test_Input/*.jpg') + \n",
        "              glob('/content/ISIC_2019_Training_Input/*.jpg'):\n",
        "    # load image\n",
        "    img = Image.open(path)\n",
        "    # resize\n",
        "    resized_size = np.array([img.width, img.height])*desired_size//max(img.size)\n",
        "    img = img.resize(resized_size)\n",
        "    # pad\n",
        "    empty_img = Image.new(\"RGB\", (desired_size, desired_size))\n",
        "    paste_location = tuple((desired_size - resized_size)//2)\n",
        "    empty_img.paste(img, paste_location)\n",
        "    img = empty_img\n",
        "    # save img\n",
        "    img.save(path)\n",
        "  print('...Done')\n",
        "\n",
        "  # create subfolders with class name (if they do not exist yet) \n",
        "  print('\\nCreating subdirs...')\n",
        "  # path to training and test folder\n",
        "  paths = ['/content/ISIC_2019_Training_Input/',\n",
        "           '/content/ISIC_2019_Test_Input/']\n",
        "  classes = ['mel', 'nv', 'bcc', 'ak', 'bkl', 'df', 'vasc', 'scc', 'unk']\n",
        "  for path in paths:\n",
        "    print('creating subdirs in: '+path)\n",
        "    for clas in classes:\n",
        "      if not os.path.exists(path+clas):\n",
        "        os.mkdir(path+clas)\n",
        "        print('created dir: '+clas)\n",
        "      else:\n",
        "        print('dir: '+clas+' already exists')\n",
        "  print('...Done')\n",
        "\n",
        "  # obtain the class that corresponds to each img and move it to its folder.\n",
        "  print('\\nReading classing and moving images')\n",
        "  # Training data\n",
        "  with open('ISIC_2019_Training_GroundTruth.csv', 'r') as f:\n",
        "    next(f) # skip header (first line) of .csv file\n",
        "    for line in f:\n",
        "      # obtain image name and corresponding class name\n",
        "      arr = np.array(line.split(','))\n",
        "      img = arr[0]+'.jpg' # img name\n",
        "      idx = np.where( arr[1:].astype(np.float) == 1.0 )[0][0] # class-index\n",
        "      clas = classes[idx]\n",
        "      # move image (if it exists)\n",
        "      if os.path.exists(paths[0]+img):\n",
        "        os.rename(paths[0]+img, paths[0]+clas+'/'+img) # rename = move\n",
        "      else :\n",
        "        print('img not found: '+img)\n",
        "  # Test data (every class is unknown, so move everything to unk)\n",
        "  for img in glob(paths[1]+'*.jpg'):\n",
        "    name = img.split('/')[-1]\n",
        "    os.rename(img, paths[1]+'unk/'+name)\n",
        "  print('...Done')\n",
        "\n",
        "  # remove zip & csv files \n",
        "  print('\\nDeleting zip & csv files...')\n",
        "  !rm -r sample_data\n",
        "  !rm -r isic-2019-training-input.zip\n",
        "  !rm -r isic-2019-training-groundtruth.zip\n",
        "  !rm -r isic-2019-test-input.zip\n",
        "  !rm -r isic-2019-training-metadata.zip\n",
        "  !rm -r isic-2019-test-metadata.zip\n",
        "  !rm -r ISIC_2019_Training_GroundTruth.csv\n",
        "  !rm -r ISIC_2019_Training_Metadata.csv\n",
        "  !rm -r ISIC_2019_Test_Metadata.csv\n",
        "  print('...Done')\n",
        "\n",
        "\n",
        "# . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .#\n",
        "\n",
        "def dataloaders(root='/content/',\n",
        "                train_img_dir='ISIC_2019_Training_Input/',\n",
        "                test_img_dir='ISIC_2019_Test_Input/',\n",
        "                batch_size=64,\n",
        "                validation_size_percentage = 5):\n",
        "  \"\"\"\n",
        "  This function creates and returns dataloaders for the train, validation and \n",
        "  test data set.\n",
        "\n",
        "  Args:\n",
        "  root (str): root directory\n",
        "  train_img_dir (str): directory containing images of the training set\n",
        "  test_img_dir (str): directory that contains the images of the test set\n",
        "  batch_size (int): batch size\n",
        "  validation_size_percentage (int, 0...100): the train data is split into train \n",
        "    and valuation. This percentage specifies how much of the original data is \n",
        "    used as validation. The remaining percentage will be the new train data.\n",
        "  \"\"\"\n",
        "\n",
        "  # dataset transformation. Expand the dataset by adding random horzontal and \n",
        "  # vertical flips. \n",
        "  # todo: add more data transformations (but not to the test set ofcourse)\n",
        "  # todo: the training image shapes are either 1024x1024 or 600x450. This is\n",
        "  #       for the moment hotfixed by resizing it to 32x32. Note that, when \n",
        "  #       changing this, the neural net also needs to be changed\n",
        "  # todo: data normalization\n",
        "  transform_train = T.Compose([T.RandomHorizontalFlip(), \n",
        "                               T.RandomVerticalFlip(),\n",
        "                               T.Resize((32,32)),  # todo: temporary fix\n",
        "                               T.ToTensor()])\n",
        "  transform_test  = T.ToTensor()\n",
        "\n",
        "  # datasets\n",
        "  dataset_train = dset.ImageFolder(root+train_img_dir, transform=transform_train)\n",
        "  dataset_test = dset.ImageFolder(root+test_img_dir, transform=transform_test)\n",
        "\n",
        "  # split train into validation and (new) train\n",
        "  N = len(dataset_train.imgs)\n",
        "  N_train = int(np.round(N*(100-validation_size_percentage)/100))\n",
        "\n",
        "  # samplers\n",
        "  sampler_train = sampler.SubsetRandomSampler(range(N_train))\n",
        "  sampler_val = sampler.SubsetRandomSampler(range(N_train, N))\n",
        "\n",
        "  # dataloaders\n",
        "  train = DataLoader(dataset_train, batch_size=batch_size, sampler=sampler_train)\n",
        "  val = DataLoader(dataset_train, batch_size=batch_size, sampler=sampler_val)\n",
        "  test = DataLoader(dataset_test, batch_size=batch_size)\n",
        "\n",
        "  # add bool to see if certain dataset is the training dataset\n",
        "  train.dataset.train = True\n",
        "  val.dataset.train = True\n",
        "  test.dataset.train = False\n",
        "\n",
        "  return train, val, test, N_train, (N-N_train), len(dataset_test.imgs)\n",
        "\n",
        "\n",
        "# . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .#\n",
        "    \n",
        "def flatten(x):\n",
        "    N = x.shape[0] # read in N, C, H, W\n",
        "    return x.view(N, -1) \n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return flatten(x)\n",
        "\n",
        "\n",
        "# . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .#\n",
        "\n",
        "def train(model, optimizer, epochs=1, backup_after_epoch=True):\n",
        "  \"\"\"\n",
        "  Trains the specified model and prints the progress\n",
        "  \n",
        "  Args:\n",
        "  model (...):  model\n",
        "  optimizer (...): optimizer\n",
        "  epochs (int): number of epochs to train the model\n",
        "\n",
        "  Returns:\n",
        "  (none)\n",
        "  \"\"\"\n",
        "  model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
        "  model.loss = []\n",
        "  model.acc_val = []\n",
        "  model.acc_test = []\n",
        "  model.elapsed_time = []\n",
        "  time_start = time.clock()\n",
        "      \n",
        "  for e in range(epochs):\n",
        "    for t, (x, y) in enumerate(dl_train):\n",
        "      model.train()  # put model to training mode\n",
        "      x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
        "      y = y.to(device=device, dtype=torch.long)\n",
        "      scores = model(x)\n",
        "      loss = F.cross_entropy(scores, y)\n",
        "      \n",
        "      # Zero out all of the gradients for the variables which the optimizer\n",
        "      # will update.\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # backward pass, comput loss gradient\n",
        "      loss.backward()\n",
        "\n",
        "      # update parameters using gradients\n",
        "      optimizer.step()\n",
        "      \n",
        "      # append loss \n",
        "      model.loss.append(loss)\n",
        "\n",
        "      # update plot\n",
        "      if t % print_every == 0:\n",
        "        time_elapsed = time.strftime('%H:%M:%S', time.gmtime(time.clock()-time_start))\n",
        "        stri = get_accuracy(dl_val, model)\n",
        "        print('Iteration %d, loss = %.4f, time = %s, %s' % (t, loss.item(), time_elapsed, stri))\n",
        "        \n",
        "\n",
        "    my_lr_scheduler.step()\n",
        "    model.elapsed_time = time.strftime('%H:%M:%S', time.gmtime(time.clock()-time_start))\n",
        "    if backup_after_epoch:\n",
        "      model.backup_to_drive()\n",
        "\n",
        "    print(my_lr_scheduler.get_lr())\n",
        "\n",
        "\n",
        "# . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .#\n",
        "\n",
        "def get_accuracy(loader, model):\n",
        "  num_correct = 0\n",
        "  num_samples = 0\n",
        "  model.eval()  # set model to evaluation mode\n",
        "  with torch.no_grad():\n",
        "    for x, y in loader:\n",
        "      x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
        "      y = y.to(device=device, dtype=torch.long)\n",
        "      scores = model(x)\n",
        "      _, preds = scores.max(1)\n",
        "      num_correct += (preds == y).sum()\n",
        "      num_samples += preds.size(0)\n",
        "    acc = float(num_correct) / num_samples\n",
        "    if loader.dataset.train:\n",
        "      model.acc_test.append(acc)\n",
        "    else:\n",
        "      model.acc_val.append(acc)\n",
        "    return 'acc = %.2f, %d/%d correct' % (100 * acc, num_correct, num_samples)\n",
        "\n",
        "\n",
        "# . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .#\n",
        "\n",
        "def visualize(model):\n",
        "  fig=plt.figure(figsize=(12, 6), dpi= 80, facecolor='w', edgecolor='k')\n",
        "  x = np.array(range(len(model.loss)))\n",
        "  plt.plot(x, model.loss)\n",
        "  plt.ylabel('Loss')\n",
        "  plt.xlabel('Iterations')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "# -------------------------------- Neural Net -------------------------------- #\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, \n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, \n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, \n",
        "                          stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "# . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .#\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "  def __init__(self, block, num_classes=9):\n",
        "    super(ResNet, self).__init__()\n",
        "    self.backup_restore_name_prefix = 'resnet18_'\n",
        "    self.backup_restore_path = '/content/drive/My Drive/5LSM0-final-assignment/'\n",
        "\n",
        "    self.in_planes = 64\n",
        "\n",
        "    self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, \n",
        "                            bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(64)\n",
        "    self.layer1 = self._make_layer(block, 64, stride=1)\n",
        "    self.layer2 = self._make_layer(block, 128, stride=2)\n",
        "    self.layer3 = self._make_layer(block, 256, stride=2)\n",
        "    self.layer4 = self._make_layer(block, 512, stride=2)\n",
        "    self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "  def _make_layer(self, block, planes, stride):\n",
        "    strides = [stride,1] \n",
        "    layers = []\n",
        "    for stride in strides:\n",
        "      layers.append(block(self.in_planes, planes, stride))\n",
        "      self.in_planes = planes * block.expansion\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = F.relu(self.bn1(self.conv1(x)))\n",
        "    out = self.layer1(out)\n",
        "    out = self.layer2(out)\n",
        "    out = self.layer3(out)\n",
        "    out = self.layer4(out)\n",
        "    out = F.avg_pool2d(out, 4)\n",
        "    out = out.view(out.size(0), -1)\n",
        "    out = self.linear(out)\n",
        "    return out\n",
        "\n",
        "  def backup_to_drive(self):\n",
        "    date_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "    path = self.backup_restore_path + self.backup_restore_name_prefix + date_time+'.pt'\n",
        "    torch.save(model.state_dict(), path)\n",
        "\n",
        "  def restore_from_drive(self, path):\n",
        "    self.load_state_dict(torch.load(path))\n",
        "    self.eval()\n",
        "\n",
        "  def restore_latest(self):\n",
        "    models = glob(self.backup_restore_path + self.backup_restore_name_prefix + '*.pt')\n",
        "    try:\n",
        "      self.restore_from_drive(models[-1])\n",
        "    except:\n",
        "      print('Error during restoring latest backup')\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "# . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .#\n",
        "\n",
        "def ResNet18():\n",
        "    return ResNet(BasicBlock)\n",
        "\n",
        "\n",
        "# ------------------------------ Initialization ------------------------------ #\n",
        "\n",
        "# check if gpu/tpu is enabled\n",
        "if torch.cuda.is_available() == False:\n",
        "  raise ValueError('GPU/TPU not enabled. Goto runtime -> change runtime type')\n",
        "\n",
        "# use gpu/tpu\n",
        "device = torch.device('cuda')\n",
        "\n",
        "# set variable type\n",
        "dtype = torch.float32\n",
        "\n",
        "# download data\n",
        "download_and_organize()\n",
        "\n",
        "# batch size, increase this until the RAM is full\n",
        "batch_size = 128 # 128 -> ~200 iterations = 1 epoch\n",
        "\n",
        "# create data loader objects for train, validation and test set. N_epoch is the\n",
        "# number of images in 1 epoch\n",
        "dl_train, dl_val, dl_test, N_epoch, N_val, N_test = dataloaders(batch_size=batch_size)\n",
        "\n",
        "# when to print\n",
        "print_every = 10\n",
        "\n",
        "\n",
        "# ----------------------------------- Main ----------------------------------- #\n",
        "\n",
        "# restore last backup of model?\n",
        "load_backup = False\n",
        "\n",
        "# learning rate (with decay)\n",
        "# todo: make a script that runs the model with different rates\n",
        "learning_rate = 1e-4\n",
        "decayRate = 0.99\n",
        "\n",
        "# model\n",
        "model = ResNet18()\n",
        "\n",
        "# load backup\n",
        "if load_backup:\n",
        "  model.restore_latest()\n",
        "\n",
        "# optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# learning rate\n",
        "my_lr_scheduler = optim.lr_scheduler.ExponentialLR(optimizer=optimizer, \n",
        "                                                         gamma=decayRate)\n",
        "\n",
        "# train\n",
        "train(model, optimizer, epochs=10)\n",
        "\n",
        "# visualize results\n",
        "visualize(model)\n",
        "\n",
        "# # save obtained model\n",
        "# model.backup_to_drive()\n",
        "\n",
        "\n",
        "# ----------------------------------- End ------------------------------------ #\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Mounting Google Drive...\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "...Done\n",
            "\n",
            "Downloading...\n",
            "Downloading isic-2019-training-input.zip to /content\n",
            "100% 9.10G/9.10G [03:32<00:00, 37.6MB/s]\n",
            "100% 9.10G/9.10G [03:32<00:00, 46.0MB/s]\n",
            "Downloading isic-2019-training-groundtruth.zip to /content\n",
            "  0% 0.00/79.7k [00:00<?, ?B/s]\n",
            "100% 79.7k/79.7k [00:00<00:00, 37.4MB/s]\n",
            "Downloading isic-2019-test-input.zip to /content\n",
            "100% 3.55G/3.56G [01:26<00:00, 29.0MB/s]\n",
            "100% 3.56G/3.56G [01:26<00:00, 44.1MB/s]\n",
            "...Done\n",
            "\n",
            "Unzipping...\n",
            "...Done\n",
            "\n",
            "Creating subdirs...\n",
            "creating subdirs in: /content/ISIC_2019_Training_Input/\n",
            "created dir: mel\n",
            "created dir: nv\n",
            "created dir: bcc\n",
            "created dir: ak\n",
            "created dir: bkl\n",
            "created dir: df\n",
            "created dir: vasc\n",
            "created dir: scc\n",
            "created dir: unk\n",
            "creating subdirs in: /content/ISIC_2019_Test_Input/\n",
            "created dir: mel\n",
            "created dir: nv\n",
            "created dir: bcc\n",
            "created dir: ak\n",
            "created dir: bkl\n",
            "created dir: df\n",
            "created dir: vasc\n",
            "created dir: scc\n",
            "created dir: unk\n",
            "...Done\n",
            "\n",
            "Reading classing and moving images\n",
            "...Done\n",
            "\n",
            "Deleting zip & csv files...\n",
            "rm: cannot remove 'isic-2019-training-metadata.zip': No such file or directory\n",
            "rm: cannot remove 'isic-2019-test-metadata.zip': No such file or directory\n",
            "rm: cannot remove 'ISIC_2019_Training_Metadata.csv': No such file or directory\n",
            "rm: cannot remove 'ISIC_2019_Test_Metadata.csv': No such file or directory\n",
            "...Done\n",
            "Iteration 0, loss = 2.4807, time = 00:00:02, acc = 0.00, 0/1267 correct\n",
            "Iteration 10, loss = 1.2811, time = 00:00:59, acc = 0.00, 0/1267 correct\n",
            "Iteration 20, loss = 1.1321, time = 00:01:54, acc = 0.00, 0/1267 correct\n",
            "Iteration 30, loss = 1.1118, time = 00:02:49, acc = 0.24, 3/1267 correct\n",
            "Iteration 40, loss = 1.0169, time = 00:03:44, acc = 12.31, 156/1267 correct\n",
            "Iteration 50, loss = 0.9630, time = 00:04:39, acc = 15.86, 201/1267 correct\n",
            "Iteration 60, loss = 0.9544, time = 00:05:34, acc = 18.71, 237/1267 correct\n",
            "Iteration 70, loss = 0.9503, time = 00:06:28, acc = 22.34, 283/1267 correct\n",
            "Iteration 80, loss = 0.9267, time = 00:07:23, acc = 18.86, 239/1267 correct\n",
            "Iteration 90, loss = 0.9270, time = 00:08:18, acc = 23.68, 300/1267 correct\n",
            "Iteration 100, loss = 0.8805, time = 00:09:12, acc = 28.33, 359/1267 correct\n",
            "Iteration 110, loss = 0.9569, time = 00:10:07, acc = 15.31, 194/1267 correct\n",
            "Iteration 120, loss = 1.0195, time = 00:11:02, acc = 25.18, 319/1267 correct\n",
            "Iteration 130, loss = 0.9459, time = 00:11:56, acc = 24.47, 310/1267 correct\n",
            "Iteration 140, loss = 0.9354, time = 00:12:50, acc = 15.71, 199/1267 correct\n",
            "Iteration 150, loss = 1.0891, time = 00:13:45, acc = 21.39, 271/1267 correct\n",
            "Iteration 160, loss = 0.8119, time = 00:14:39, acc = 24.55, 311/1267 correct\n",
            "Iteration 170, loss = 0.9253, time = 00:15:33, acc = 22.57, 286/1267 correct\n",
            "Iteration 180, loss = 0.9455, time = 00:16:28, acc = 26.60, 337/1267 correct\n",
            "[9.801e-05]\n",
            "Iteration 0, loss = 1.0473, time = 00:17:18, acc = 25.10, 318/1267 correct\n",
            "Iteration 10, loss = 1.0089, time = 00:18:12, acc = 22.57, 286/1267 correct\n",
            "Iteration 20, loss = 0.9462, time = 00:19:05, acc = 23.60, 299/1267 correct\n",
            "Iteration 30, loss = 0.9279, time = 00:19:58, acc = 24.70, 313/1267 correct\n",
            "Iteration 40, loss = 1.0552, time = 00:20:51, acc = 20.28, 257/1267 correct\n",
            "Iteration 50, loss = 0.9801, time = 00:21:46, acc = 24.55, 311/1267 correct\n",
            "Iteration 60, loss = 0.9336, time = 00:22:41, acc = 24.47, 310/1267 correct\n",
            "Iteration 70, loss = 0.9673, time = 00:23:36, acc = 24.70, 313/1267 correct\n",
            "Iteration 80, loss = 0.9755, time = 00:24:30, acc = 24.47, 310/1267 correct\n",
            "Iteration 90, loss = 0.8022, time = 00:25:24, acc = 23.91, 303/1267 correct\n",
            "Iteration 100, loss = 0.9020, time = 00:26:17, acc = 20.84, 264/1267 correct\n",
            "Iteration 110, loss = 0.9624, time = 00:27:11, acc = 21.70, 275/1267 correct\n",
            "Iteration 120, loss = 0.9010, time = 00:28:06, acc = 20.68, 262/1267 correct\n",
            "Iteration 130, loss = 0.8631, time = 00:29:01, acc = 22.81, 289/1267 correct\n",
            "Iteration 140, loss = 0.9269, time = 00:29:55, acc = 19.97, 253/1267 correct\n",
            "Iteration 150, loss = 0.8841, time = 00:30:49, acc = 20.99, 266/1267 correct\n",
            "Iteration 160, loss = 0.8630, time = 00:31:44, acc = 25.41, 322/1267 correct\n",
            "Iteration 170, loss = 1.0101, time = 00:32:38, acc = 23.13, 293/1267 correct\n",
            "Iteration 180, loss = 0.9678, time = 00:33:33, acc = 25.89, 328/1267 correct\n",
            "[9.70299e-05]\n",
            "Iteration 0, loss = 0.8032, time = 00:34:22, acc = 21.07, 267/1267 correct\n",
            "Iteration 10, loss = 0.7335, time = 00:35:17, acc = 20.99, 266/1267 correct\n",
            "Iteration 20, loss = 0.7557, time = 00:36:11, acc = 21.94, 278/1267 correct\n",
            "Iteration 30, loss = 0.9403, time = 00:37:06, acc = 24.47, 310/1267 correct\n",
            "Iteration 40, loss = 0.7979, time = 00:38:00, acc = 24.63, 312/1267 correct\n",
            "Iteration 50, loss = 0.8265, time = 00:38:54, acc = 21.23, 269/1267 correct\n",
            "Iteration 60, loss = 0.9664, time = 00:39:49, acc = 26.28, 333/1267 correct\n",
            "Iteration 70, loss = 0.9100, time = 00:40:42, acc = 22.10, 280/1267 correct\n",
            "Iteration 80, loss = 0.7657, time = 00:41:37, acc = 26.36, 334/1267 correct\n",
            "Iteration 90, loss = 0.8611, time = 00:42:30, acc = 21.07, 267/1267 correct\n",
            "Iteration 100, loss = 0.9284, time = 00:43:25, acc = 24.15, 306/1267 correct\n",
            "Iteration 110, loss = 0.8165, time = 00:44:19, acc = 24.94, 316/1267 correct\n",
            "Iteration 120, loss = 0.9661, time = 00:45:14, acc = 23.60, 299/1267 correct\n",
            "Iteration 130, loss = 0.9980, time = 00:46:09, acc = 21.39, 271/1267 correct\n",
            "Iteration 140, loss = 0.8903, time = 00:47:04, acc = 22.10, 280/1267 correct\n",
            "Iteration 150, loss = 0.9400, time = 00:47:59, acc = 22.02, 279/1267 correct\n",
            "Iteration 160, loss = 0.9352, time = 00:48:54, acc = 23.99, 304/1267 correct\n",
            "Iteration 170, loss = 0.8449, time = 00:49:50, acc = 22.18, 281/1267 correct\n",
            "Iteration 180, loss = 0.7954, time = 00:50:46, acc = 26.60, 337/1267 correct\n",
            "[9.605960100000001e-05]\n",
            "Iteration 0, loss = 0.7853, time = 00:51:36, acc = 22.02, 279/1267 correct\n",
            "Iteration 10, loss = 0.8196, time = 00:52:31, acc = 22.73, 288/1267 correct\n",
            "Iteration 20, loss = 0.7747, time = 00:53:26, acc = 25.02, 317/1267 correct\n",
            "Iteration 30, loss = 0.9101, time = 00:54:20, acc = 23.36, 296/1267 correct\n",
            "Iteration 40, loss = 0.8713, time = 00:55:15, acc = 25.97, 329/1267 correct\n",
            "Iteration 50, loss = 0.9192, time = 00:56:10, acc = 22.26, 282/1267 correct\n",
            "Iteration 60, loss = 0.8786, time = 00:57:04, acc = 23.60, 299/1267 correct\n",
            "Iteration 70, loss = 0.8522, time = 00:57:59, acc = 20.05, 254/1267 correct\n",
            "Iteration 80, loss = 0.8394, time = 00:58:54, acc = 26.44, 335/1267 correct\n",
            "Iteration 90, loss = 0.8599, time = 00:59:48, acc = 19.42, 246/1267 correct\n",
            "Iteration 100, loss = 0.7259, time = 01:00:43, acc = 23.28, 295/1267 correct\n",
            "Iteration 110, loss = 0.8883, time = 01:01:37, acc = 24.15, 306/1267 correct\n",
            "Iteration 120, loss = 0.6731, time = 01:02:32, acc = 25.10, 318/1267 correct\n",
            "Iteration 130, loss = 0.8628, time = 01:03:27, acc = 25.10, 318/1267 correct\n",
            "Iteration 140, loss = 0.8874, time = 01:04:21, acc = 24.47, 310/1267 correct\n",
            "Iteration 150, loss = 0.7824, time = 01:05:16, acc = 21.86, 277/1267 correct\n",
            "Iteration 160, loss = 0.8667, time = 01:06:10, acc = 19.65, 249/1267 correct\n",
            "Iteration 170, loss = 0.9074, time = 01:07:05, acc = 23.60, 299/1267 correct\n",
            "Iteration 180, loss = 0.8175, time = 01:08:00, acc = 25.89, 328/1267 correct\n",
            "[9.509900499000001e-05]\n",
            "Iteration 0, loss = 0.8104, time = 01:08:49, acc = 24.07, 305/1267 correct\n",
            "Iteration 10, loss = 0.8717, time = 01:09:44, acc = 21.15, 268/1267 correct\n",
            "Iteration 20, loss = 0.7669, time = 01:10:40, acc = 21.39, 271/1267 correct\n",
            "Iteration 30, loss = 0.7357, time = 01:11:37, acc = 23.68, 300/1267 correct\n",
            "Iteration 40, loss = 0.7670, time = 01:12:34, acc = 22.73, 288/1267 correct\n",
            "Iteration 50, loss = 0.7081, time = 01:13:30, acc = 27.78, 352/1267 correct\n",
            "Iteration 60, loss = 0.8250, time = 01:14:27, acc = 24.23, 307/1267 correct\n",
            "Iteration 70, loss = 0.7777, time = 01:15:24, acc = 17.84, 226/1267 correct\n",
            "Iteration 80, loss = 0.8215, time = 01:16:21, acc = 24.78, 314/1267 correct\n",
            "Iteration 90, loss = 0.8677, time = 01:17:15, acc = 21.47, 272/1267 correct\n",
            "Iteration 100, loss = 0.7797, time = 01:18:10, acc = 22.89, 290/1267 correct\n",
            "Iteration 110, loss = 0.8230, time = 01:19:05, acc = 25.41, 322/1267 correct\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-92e0eac70e4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;31m# train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;31m# visualize results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-92e0eac70e4c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, epochs, backup_after_epoch)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# put model to training mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# move to device, e.g. GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[1;32m    137\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;31m# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2816\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2818\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2820\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}