{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "TUE_5LSM0_g6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vorst4/TUE_5LSM0_g6/blob/master/TUE_5LSM0_g6_finished_csv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGfJwDKxMQEw",
        "colab_type": "code",
        "outputId": "1f0f0f57-2363-429b-889c-6fea251df294",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "\n",
        "# ------------------------------ Import modules ------------------------------ #\n",
        "\n",
        "import os\n",
        "import json\n",
        "import importlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "from glob import glob\n",
        "from datetime import datetime\n",
        "from PIL import Image\n",
        "from google.colab import drive\n",
        "\n",
        "# ---------------------- Import modules from Git source ---------------------- #\n",
        "\n",
        "# efficient net (downloaded from Git)\n",
        "try:\n",
        "  from EfficientNet.efficientnet_pytorch.model import EfficientNet\n",
        "except:\n",
        "  print('\\nInstalling efficient-net...')\n",
        "  !git clone https://github.com/lukemelas/EfficientNet-PyTorch\n",
        "  os.rename('EfficientNet-PyTorch', 'EfficientNet')\n",
        "  from EfficientNet.efficientnet_pytorch.model import EfficientNet\n",
        "  print('Done')\n",
        "\n",
        "# shap\n",
        "try:\n",
        "  import shap\n",
        "except:\n",
        "  print('\\nInstalling shap...')\n",
        "  !pip install shap\n",
        "  import shap\n",
        "  print('Done')\n",
        "\n",
        "# # classification scores of isic challenge\n",
        "# try:\n",
        "#   from isic_challenge_scoring.isic_challenge_scoring.classification import ClassificationScore\n",
        "# except:\n",
        "#   print('\\nInstalling isic-challenge-scoring...')\n",
        "#   !git clone https://github.com/ImageMarkup/isic-challenge-scoring.git\n",
        "#   os.rename('isic-challenge-scoring', 'isic_challenge_scoring')\n",
        "#   from isic_challenge_scoring.isic_challenge_scoring.classification import ClassificationScore\n",
        "#   print('Done')\n",
        "\n",
        "\n",
        "# ----------------------------- Initialize Colab ----------------------------- #\n",
        "#\n",
        "# NOTE: all console commands (the ones that start with !) cannot be run from a \n",
        "# .py script. Usually this is possible using the command 'os.system('...')'.\n",
        "# However, in Colab, it is for some reason not possible to obtain the console\n",
        "# output of the command that is run. This makes it impossible to notify the user\n",
        "# if an error occurs. All the commands therefore need to be run in the main\n",
        "# .ipynb script (which is this script).\n",
        "#\n",
        "\n",
        "\n",
        "# check if GPU is enabled\n",
        "if torch.cuda.is_available() == False:\n",
        "  print('\\nWARNING: GPU not enabled. Goto runtime -> change runtime type')\n",
        "\n",
        "\n",
        "# mount Google Drive (if needed)\n",
        "if not os.path.exists('drive'):\n",
        "  print('\\nMounting Google Drive...')\n",
        "  drive.mount('/content/drive')\n",
        "  print('Done')\n",
        "\n",
        "\n",
        "# setup Git (if needed)\n",
        "if not os.path.exists('TUE_5LSM0_g6'):\n",
        "  print('\\nSetting up git...')\n",
        "  print('...Loading github.json from Google Drive')\n",
        "  with open('/content/drive/My Drive/github.json', 'r') as json_file:\n",
        "    gitconfig = json.load(json_file)\n",
        "  print('...Cloning git repo')\n",
        "  url = 'https://'+gitconfig[\"username\"]+':'+gitconfig[\"key\"]+\\\n",
        "        '@github.com/vorst4/TUE_5LSM0_g6.git'\n",
        "  !git clone {url}\n",
        "  print('...Setting username and email')\n",
        "  !git -C TUE_5LSM0_g6 config user.name {gitconfig[\"username\"]}\n",
        "  !git -C TUE_5LSM0_g6 config user.email {gitconfig[\"email\"]}\n",
        "  print('Done')\n",
        "\n",
        "\n",
        "# remove default sample_data folder (if needed)\n",
        "if os.path.exists('sample_data'):\n",
        "  print('\\nRemoving sample_data...')\n",
        "  os.system('rm -r sample_data')\n",
        "  print('Done')\n",
        "\n",
        "\n",
        "# copy and unzip data from Google Drive (if needed)\n",
        "if not os.path.exists('ISIC_2019_Test_Input'):\n",
        "  print('\\nGetting data...')\n",
        "  print('...Copying data.zip from Google Drive to workfolder')\n",
        "  !cp 'drive/My Drive/5LSM0-final-assignment/data.zip' .\n",
        "  print('...Unpacking data.zip')\n",
        "  !unzip -q data.zip\n",
        "  print('...Removing data.zip')\n",
        "  !rm data.zip\n",
        "  print('Done\\n')\n",
        "\n",
        "\n",
        "# ----------------------------- Import Functions ----------------------------- #\n",
        "#\n",
        "# NOTE: The modules need to be forcibly reloaded because Colab does not do this\n",
        "# by default, even if the module has changed.\n",
        "#\n",
        "\n",
        "# dataloaders\n",
        "import TUE_5LSM0_g6.dataloaders\n",
        "importlib.reload(TUE_5LSM0_g6.dataloaders)\n",
        "dataloaders = TUE_5LSM0_g6.dataloaders.dataloaders\n",
        "\n",
        "# train & accuracy\n",
        "import TUE_5LSM0_g6.train\n",
        "importlib.reload(TUE_5LSM0_g6.train)\n",
        "train = TUE_5LSM0_g6.train.train\n",
        "accuracy = TUE_5LSM0_g6.train.accuracy\n",
        "\n",
        "# resnet18\n",
        "import TUE_5LSM0_g6.resnet18\n",
        "importlib.reload(TUE_5LSM0_g6.resnet18)\n",
        "resnet18 = TUE_5LSM0_g6.resnet18.resnet18\n",
        "\n",
        "# backup\n",
        "import TUE_5LSM0_g6.backup\n",
        "importlib.reload(TUE_5LSM0_g6.backup)\n",
        "backup = TUE_5LSM0_g6.backup.backup\n",
        "\n",
        "# restore\n",
        "import TUE_5LSM0_g6.restore\n",
        "importlib.reload(TUE_5LSM0_g6.restore)\n",
        "restore = TUE_5LSM0_g6.restore.restore\n",
        "\n",
        "\n",
        "# --------------------------------- Constants -------------------------------- #\n",
        "\n",
        "N_classes = 9\n",
        "\n",
        "# --------------------------------- Settings --------------------------------- #\n",
        "\n",
        "# settings object\n",
        "S = type('settings', (), {})()\n",
        "\n",
        "# use gpu/cpu\n",
        "if torch.cuda.is_available():\n",
        "  S.device = torch.device('cuda')\n",
        "else:\n",
        "  S.device = torch.device('cpu')\n",
        "\n",
        "# image size (squared)\n",
        "S.modelname = 'efficientnet-b0'\n",
        "S.img_size = EfficientNet.get_image_size(S.modelname)\n",
        "\n",
        "# set variable type\n",
        "S.dtype = torch.float32\n",
        "\n",
        "# when to print\n",
        "S.print_every = 100\n",
        "\n",
        "# number of epochs to run\n",
        "S.epochs = 50\n",
        "\n",
        "# batch size, increase this until the RAM is full\n",
        "S.batch_size = 64\n",
        "\n",
        "# percentage of original train set that is to be used for validation\n",
        "S.val_ratio = 10\n",
        "\n",
        "# restore last backup of model?\n",
        "S.load_backup = True\n",
        "\n",
        "# Create backup each epoch?\n",
        "S.backup_each_epoch = True\n",
        "\n",
        "# Create backup if training is finished?\n",
        "S.backup_on_finish = False\n",
        "\n",
        "\n",
        "# ----------------------------------- Main ----------------------------------- #\n",
        "\n",
        "# create data loader objects for train, validation and test set.\n",
        "dl_train, dl_val, dl_test = dataloaders(batch_size=S.batch_size,\n",
        "                                        val_ratio = S.val_ratio,\n",
        "                                        img_size = S.img_size)\n",
        "\n",
        "# learning rate (with decay)\n",
        "# todo: make a script that runs the model with different rates\n",
        "learning_rate = 1e-3\n",
        "decayRate = 0.9\n",
        "\n",
        "# model\n",
        "# model = resnet18(S.img_size)\n",
        "\n",
        "# load pretrained efficientnet model (b0 is the smallest model). Note that img\n",
        "# size must be 224 for model b0\n",
        "if S.img_size == EfficientNet.get_image_size(S.modelname):\n",
        "  model = EfficientNet.from_pretrained(S.modelname, N_classes)\n",
        "  # model = EfficientNet.from_name(S.modelname, N_classes)\n",
        "\n",
        "\n",
        "# load non-pretrained model (compare these two later on)\n",
        "# model = EfficientNet.from_pretrained('efficientnet-b0')\n",
        "\n",
        "# print layer sizes\n",
        "# model.print_layer_sizes()\n",
        "\n",
        "\n",
        "# load backup\n",
        "if S.load_backup:\n",
        "  model = restore(model, S.modelname)\n",
        "\n",
        "# optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# learning rate\n",
        "lr_exp = optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=decayRate)\n",
        "\n",
        "# train\n",
        "# train(model, optimizer, dl_train, dl_val, lr_exp, S)\n",
        "\n",
        "# visualize results\n",
        "# model.visualize()\n",
        "\n",
        "# save obtained model (not needed if it is already saved after each epoch)\n",
        "if S.backup_on_finish and not S.backup_each_epoch:\n",
        "  backup(model, S.modelname)\n",
        "\n",
        "# # get accuracy best model\n",
        "# best_model = model\n",
        "# accuracy(dl_test, best_model)\n",
        "\n",
        "# create csv file of test data\n",
        "make_cvs(model)\n",
        "\n",
        "\n",
        "# ----------------------------------- End ------------------------------------ #\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: GPU not enabled. Goto runtime -> change runtime type\n",
            "Loaded pretrained weights for efficientnet-b0\n",
            "\n",
            "WARNING: Using CPU !!!\n",
            "Restored model\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rkbwum3UmL6w",
        "colab_type": "code",
        "outputId": "698bd153-d35c-4e21-f9a0-4b304d5bed86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "# ------------------------- GIT Pull, Commit & Push -------------------------- #\n",
        "\n",
        "def git():\n",
        "\n",
        "  if not input('\\nPull? (y)') == 'y':\n",
        "    return\n",
        "  !git -C /content/TUE_5LSM0_g6 pull\n",
        "\n",
        "  commit_msg = '\\''+input('\\nEnter commit message: ')+'\\''\n",
        "\n",
        "  if not input('\\nCommit? (y)') == 'y':\n",
        "    return\n",
        "  !git -C /content/TUE_5LSM0_g6 add .\n",
        "  !git -C /content/TUE_5LSM0_g6 commit -m {commit_msg}\n",
        "\n",
        "  if not input('\\nPush? (y)') == 'y':\n",
        "    return\n",
        "  !git -C /content/TUE_5LSM0_g6 push\n",
        "\n",
        "git()\n",
        "\n",
        "# ----------------------------------- End ------------------------------------ #\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Pull? (y)y\n",
            "Already up to date.\n",
            "\n",
            "Enter commit message: updated restor.py such that a model from a gpu-device can be loded onto cpu-device\n",
            "\n",
            "Commit? (y)y\n",
            "[master e7933d4] updated restor.py such that a model from a gpu-device can be loded onto cpu-device\n",
            " 1 file changed, 10 insertions(+), 5 deletions(-)\n",
            "\n",
            "Push? (y)y\n",
            "Counting objects: 3, done.\n",
            "Delta compression using up to 2 threads.\n",
            "Compressing objects: 100% (3/3), done.\n",
            "Writing objects: 100% (3/3), 535 bytes | 535.00 KiB/s, done.\n",
            "Total 3 (delta 2), reused 0 (delta 0)\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/vorst4/TUE_5LSM0_g6.git\n",
            "   541955a..e7933d4  master -> master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFe1qFwU_Adt",
        "colab_type": "code",
        "outputId": "69b18eb2-cbc0-4d24-d189-c59ce3f3e553",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 733
        }
      },
      "source": [
        "\n",
        "# fig=plt.figure(figsize=(12, 6), dpi= 80, facecolor='w', edgecolor='k')\n",
        "# x = np.array(range(len(model.acc_val)))\n",
        "# plt.plot(x, model.acc_val)\n",
        "# plt.ylabel('Loss')\n",
        "# plt.xlabel('Iterations')\n",
        "# plt.ylim([0.6, 0.8])\n",
        "# plt.show()\n",
        "\n",
        "for att in dir(model):\n",
        "  if not att[0] == '_':\n",
        "    print(att)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "add_module\n",
            "apply\n",
            "bfloat16\n",
            "buffers\n",
            "children\n",
            "cpu\n",
            "cuda\n",
            "double\n",
            "dump_patches\n",
            "eval\n",
            "extra_repr\n",
            "extract_features\n",
            "float\n",
            "forward\n",
            "from_name\n",
            "from_pretrained\n",
            "get_image_size\n",
            "half\n",
            "load_state_dict\n",
            "modules\n",
            "named_buffers\n",
            "named_children\n",
            "named_modules\n",
            "named_parameters\n",
            "parameters\n",
            "register_backward_hook\n",
            "register_buffer\n",
            "register_forward_hook\n",
            "register_forward_pre_hook\n",
            "register_parameter\n",
            "requires_grad_\n",
            "set_swish\n",
            "share_memory\n",
            "state_dict\n",
            "to\n",
            "train\n",
            "training\n",
            "type\n",
            "zero_grad\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}