{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "TUE_5LSM0_g6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02b9e8912f2344f789e4fcb1475a7edc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_497171d3ef594fc6b142cc403fcc4970",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c3e9f18d96c147cd847aa1713d9f7116",
              "IPY_MODEL_b0c37deb67984f19b441782185a031ce"
            ]
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vorst4/TUE_5LSM0_g6/blob/master/TUE_5LSM0_g6_dennis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGfJwDKxMQEw",
        "colab_type": "code",
        "outputId": "08ced776-1c2a-420b-da90-71f0c3ae4ca9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366,
          "referenced_widgets": [
            "02b9e8912f2344f789e4fcb1475a7edc"
          ]
        }
      },
      "source": [
        "\n",
        "# ------------------------------ Import modules ------------------------------ #\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import importlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "from glob import glob\n",
        "from datetime import datetime\n",
        "from PIL import Image\n",
        "from google.colab import drive\n",
        "\n",
        "try:\n",
        "  import rdp\n",
        "except:\n",
        "  !pip install rdp\n",
        "  import rdp\n",
        "\n",
        "# ---------------------- Import modules from Git source ---------------------- #\n",
        "\n",
        "# efficient net\n",
        "try:\n",
        "  from src.efficientnet.efficientnet_pytorch.model import EfficientNet\n",
        "except:\n",
        "  print('\\nInstalling efficient-net...')\n",
        "  !pip install -e git+https://github.com/lukemelas/EfficientNet-PyTorch#egg=EfficientNet\n",
        "  from src.efficientnet.efficientnet_pytorch.model import EfficientNet\n",
        "  print('Done')\n",
        "\n",
        "# # shap\n",
        "# try:\n",
        "#   import shap\n",
        "# except:\n",
        "#   print('\\nInstalling shap...')\n",
        "#   !pip install shap\n",
        "#   import shap\n",
        "#   print('Done')\n",
        "\n",
        "\n",
        "# ----------------------------- Initialize Colab ----------------------------- #\n",
        "#\n",
        "# NOTE: all console commands (the ones that start with !) cannot be run from a \n",
        "# .py script. Usually this is possible using the command 'os.system('...')'.\n",
        "# However, in Colab, it is for some reason not possible to obtain the console\n",
        "# output of the command that is run. This makes it impossible to notify the user\n",
        "# if an error occurs. All the commands therefore need to be run in the main\n",
        "# .ipynb script (which is this script).\n",
        "#\n",
        "\n",
        "\n",
        "# check if GPU is enabled\n",
        "if torch.cuda.is_available() == False:\n",
        "  print('\\nWARNING: GPU not enabled. Goto runtime -> change runtime type')\n",
        "\n",
        "\n",
        "# mount Google Drive (if needed)\n",
        "if not os.path.exists('drive'):\n",
        "  print('\\nMounting Google Drive...')\n",
        "  drive.mount('/content/drive')\n",
        "  print('Done')\n",
        "\n",
        "\n",
        "# setup Git (if needed)\n",
        "if not os.path.exists('TUE_5LSM0_g6'):\n",
        "  print('\\nSetting up git...')\n",
        "  print('...Loading github.json from Google Drive')\n",
        "  with open('/content/drive/My Drive/github.json', 'r') as json_file:\n",
        "    gitconfig = json.load(json_file)\n",
        "  print('...Cloning git repo')\n",
        "  url = 'https://'+gitconfig[\"username\"]+':'+gitconfig[\"key\"]+\\\n",
        "        '@github.com/vorst4/TUE_5LSM0_g6.git'\n",
        "  !git clone {url}\n",
        "  print('...Setting username and email')\n",
        "  !git -C TUE_5LSM0_g6 config user.name {gitconfig[\"username\"]}\n",
        "  !git -C TUE_5LSM0_g6 config user.email {gitconfig[\"email\"]}\n",
        "  print('Done')\n",
        "\n",
        "\n",
        "# remove default sample_data folder (if needed)\n",
        "if os.path.exists('sample_data'):\n",
        "  print('\\nRemoving sample_data...')\n",
        "  os.system('rm -r sample_data')\n",
        "  print('Done')\n",
        "\n",
        "\n",
        "# copy and unzip data from Google Drive (if needed)\n",
        "if not os.path.exists('ISIC_2019_Test_Input'):\n",
        "  print('\\nGetting data...')\n",
        "  print('...Copying data.zip from Google Drive to workfolder')\n",
        "  !cp 'drive/My Drive/5LSM0-final-assignment/data.zip' .\n",
        "  print('...Unpacking data.zip')\n",
        "  !unzip -q data.zip\n",
        "  print('...Removing data.zip')\n",
        "  !rm data.zip\n",
        "  print('Done\\n')\n",
        "\n",
        "\n",
        "# ----------------------------- Import Functions ----------------------------- #\n",
        "#\n",
        "# NOTE: The modules need to be forcibly reloaded because Colab does not do this\n",
        "# by default, even if the module has changed.\n",
        "#\n",
        "\n",
        "# append git dir to systems paths\n",
        "sys.path.append('TUE_5LSM0_g6')\n",
        "\n",
        "# dataloaders\n",
        "import dataloaders\n",
        "importlib.reload(dataloaders)\n",
        "dataloaders = dataloaders.dataloaders\n",
        "\n",
        "# train & accuracy\n",
        "import train\n",
        "importlib.reload(train)\n",
        "train = train.train\n",
        "accuracy = TUE_5LSM0_g6.train.accuracy\n",
        "\n",
        "# resnet18\n",
        "import resnet18\n",
        "importlib.reload(resnet18)\n",
        "resnet18 = resnet18.resnet18\n",
        "\n",
        "# backup\n",
        "import backup\n",
        "importlib.reload(backup)\n",
        "backup = backup.backup\n",
        "\n",
        "# restore\n",
        "import restore\n",
        "importlib.reload(restore)\n",
        "restore = restore.restore\n",
        "\n",
        "# isic_challenge_scoring (module, that does not change)\n",
        "from isic_challenge_scoring.classification import ClassificationScore\n",
        "\n",
        "\n",
        "# --------------------------------- Constants -------------------------------- #\n",
        "\n",
        "N_classes = 9\n",
        "\n",
        "# --------------------------------- Settings --------------------------------- #\n",
        "\n",
        "# settings object\n",
        "S = type('settings', (), {})()\n",
        "\n",
        "# use gpu/cpu\n",
        "if torch.cuda.is_available():\n",
        "  S.device = torch.device('cuda')\n",
        "else:\n",
        "  S.device = torch.device('cpu')\n",
        "\n",
        "# image size (squared)\n",
        "S.modelname = 'efficientnet-b0'\n",
        "S.img_size = EfficientNet.get_image_size(S.modelname)\n",
        "\n",
        "# set variable type\n",
        "S.dtype = torch.float32\n",
        "\n",
        "# when to print\n",
        "S.print_every = 100\n",
        "\n",
        "# number of epochs to run\n",
        "S.epochs = 50\n",
        "\n",
        "# batch size, increase this until the RAM is full\n",
        "S.batch_size = 64\n",
        "\n",
        "# percentage of original train set that is to be used for validation\n",
        "S.val_ratio = 10\n",
        "\n",
        "# restore last backup of model?\n",
        "S.load_backup = True\n",
        "\n",
        "# Create backup each epoch?\n",
        "S.backup_each_epoch = False\n",
        "\n",
        "# Create backup if training is finished?\n",
        "S.backup_on_finish = False\n",
        "\n",
        "\n",
        "# ----------------------------------- Main ----------------------------------- #\n",
        "\n",
        "# create data loader objects for train, validation and test set.\n",
        "dl_train, dl_val, dl_test = dataloaders(batch_size=S.batch_size,\n",
        "                                        val_ratio = S.val_ratio,\n",
        "                                        img_size = S.img_size)\n",
        "\n",
        "# learning rate (with decay)\n",
        "# todo: make a script that runs the model with different rates\n",
        "learning_rate = 1e-3\n",
        "decayRate = 0.9\n",
        "\n",
        "# model\n",
        "# model = resnet18(S.img_size)\n",
        "\n",
        "# load pretrained efficientnet model (b0 is the smallest model). Note that img\n",
        "# size must be 224 for model b0\n",
        "if S.img_size == EfficientNet.get_image_size(S.modelname):\n",
        "  model = EfficientNet.from_pretrained(S.modelname, N_classes)\n",
        "  # model = EfficientNet.from_name(S.modelname, N_classes)\n",
        "\n",
        "\n",
        "# load non-pretrained model (compare these two later on)\n",
        "# model = EfficientNet.from_pretrained('efficientnet-b0')\n",
        "\n",
        "# print layer sizes\n",
        "# model.print_layer_sizes()\n",
        "\n",
        "\n",
        "# load backup\n",
        "if S.load_backup:\n",
        "  model = restore(model, S.modelname)\n",
        "\n",
        "# optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# learning rate\n",
        "lr_exp = optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=decayRate)\n",
        "\n",
        "# train\n",
        "# train(model, optimizer, dl_train, dl_val, lr_exp, S)\n",
        "\n",
        "# visualize results\n",
        "# model.visualize()\n",
        "\n",
        "# save obtained model (not needed if it is already saved after each epoch)\n",
        "if S.backup_on_finish and not S.backup_each_epoch:\n",
        "  backup(model, S.modelname)\n",
        "\n",
        "# # get accuracy best model\n",
        "# best_model = model\n",
        "# accuracy(dl_test, best_model)\n",
        "\n",
        "# create csv file of test data\n",
        "# make_cvs(model)\n",
        "\n",
        "\n",
        "# ----------------------------------- End ------------------------------------ #\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting rdp\n",
            "  Downloading https://files.pythonhosted.org/packages/67/42/80a54cc4387256335c32b48bd42db80967ab5f40d6ffcd8167b3dd988c11/rdp-0.8.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from rdp) (1.18.3)\n",
            "Building wheels for collected packages: rdp\n",
            "  Building wheel for rdp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rdp: filename=rdp-0.8-cp36-none-any.whl size=4570 sha256=7b4b2fa8e0c9bc080b9310e3d41e1f4a0f3a3bf2b96c427553a41e46cb77f904\n",
            "  Stored in directory: /root/.cache/pip/wheels/76/e4/02/c738593caece49c63180d093651bec3cd3b02ea3248f076f07\n",
            "Successfully built rdp\n",
            "Installing collected packages: rdp\n",
            "Successfully installed rdp-0.8\n",
            "\n",
            "WARNING: GPU not enabled. Goto runtime -> change runtime type\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/adv-efficientnet-b0-b64d5a18.pth\" to /root/.cache/torch/checkpoints/adv-efficientnet-b0-b64d5a18.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "02b9e8912f2344f789e4fcb1475a7edc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=21389172), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loaded pretrained weights for efficientnet-b0\n",
            "\n",
            "WARNING: Using CPU !!!\n",
            "Restored model\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rkbwum3UmL6w",
        "colab_type": "code",
        "outputId": "2a3321c1-c76a-4a12-e592-7a38ecd8f434",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        }
      },
      "source": [
        "# ------------------------- GIT Pull, Commit & Push -------------------------- #\n",
        "\n",
        "def git():\n",
        "\n",
        "  if not input('\\nPull? (y)') == 'y':\n",
        "    return\n",
        "  !git -C /content/TUE_5LSM0_g6 pull\n",
        "\n",
        "  commit_msg = '\\''+input('\\nEnter commit message: ')+'\\''\n",
        "\n",
        "  if not input('\\nCommit? (y)') == 'y':\n",
        "    return\n",
        "  !git -C /content/TUE_5LSM0_g6 add .\n",
        "  !git -C /content/TUE_5LSM0_g6 commit -m {commit_msg}\n",
        "\n",
        "  if not input('\\nPush? (y)') == 'y':\n",
        "    return\n",
        "  !git -C /content/TUE_5LSM0_g6 push\n",
        "\n",
        "git()\n",
        "\n",
        "# ----------------------------------- End ------------------------------------ #\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Pull? (y)y\n",
            "remote: Enumerating objects: 11, done.\u001b[K\n",
            "remote: Counting objects: 100% (11/11), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 9 (delta 4), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (9/9), done.\n",
            "From https://github.com/vorst4/TUE_5LSM0_g6\n",
            "   e7933d4..b78ab26  master     -> origin/master\n",
            "Updating e7933d4..b78ab26\n",
            "Fast-forward\n",
            " TUE_5LSM0_g6_finished_csv.ipynb | 456 \u001b[32m++++++++++++++++++++++++++++++++++++++++\u001b[m\n",
            " get_accuracy2.py                |  26 \u001b[32m+++\u001b[m\n",
            " make_cvs.py                     |   2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 3 files changed, 483 insertions(+), 1 deletion(-)\n",
            " create mode 100644 TUE_5LSM0_g6_finished_csv.ipynb\n",
            " create mode 100644 get_accuracy2.py\n",
            "\n",
            "Enter commit message: The published isic_challenge_scoring is for python 3.7, however colab uses 3.6.9. So I added a modified isic_challenge_scoring that is compatible with 3.6.9\n",
            "\n",
            "Commit? (y)y\n",
            "[master ef3ac4f] The published isic_challenge_scoring is for python 3.7, however colab uses 3.6.9. So I added a modified isic_challenge_scoring that is compatible with 3.6.9\n",
            " 20 files changed, 1000 insertions(+)\n",
            " create mode 100644 isic_challenge_scoring/__init__.py\n",
            " create mode 100644 isic_challenge_scoring/__main__.py\n",
            " create mode 100644 isic_challenge_scoring/__pycache__/__init__.cpython-36.pyc\n",
            " create mode 100644 isic_challenge_scoring/__pycache__/classification.cpython-36.pyc\n",
            " create mode 100644 isic_challenge_scoring/__pycache__/confusion.cpython-36.pyc\n",
            " create mode 100644 isic_challenge_scoring/__pycache__/load_csv.cpython-36.pyc\n",
            " create mode 100644 isic_challenge_scoring/__pycache__/load_image.cpython-36.pyc\n",
            " create mode 100644 isic_challenge_scoring/__pycache__/metrics.cpython-36.pyc\n",
            " create mode 100644 isic_challenge_scoring/__pycache__/segmentation.cpython-36.pyc\n",
            " create mode 100644 isic_challenge_scoring/__pycache__/types.cpython-36.pyc\n",
            " create mode 100644 isic_challenge_scoring/__pycache__/unzip.cpython-36.pyc\n",
            " create mode 100644 isic_challenge_scoring/classification.py\n",
            " create mode 100644 isic_challenge_scoring/confusion.py\n",
            " create mode 100644 isic_challenge_scoring/load_csv.py\n",
            " create mode 100644 isic_challenge_scoring/load_image.py\n",
            " create mode 100644 isic_challenge_scoring/metrics.py\n",
            " create mode 100644 isic_challenge_scoring/segmentation.py\n",
            " create mode 100644 isic_challenge_scoring/task2.py\n",
            " create mode 100644 isic_challenge_scoring/types.py\n",
            " create mode 100644 isic_challenge_scoring/unzip.py\n",
            "\n",
            "Push? (y)y\n",
            "Counting objects: 24, done.\n",
            "Delta compression using up to 2 threads.\n",
            "Compressing objects: 100% (24/24), done.\n",
            "Writing objects: 100% (24/24), 24.59 KiB | 6.15 MiB/s, done.\n",
            "Total 24 (delta 1), reused 0 (delta 0)\n",
            "remote: Resolving deltas: 100% (1/1), completed with 1 local object.\u001b[K\n",
            "To https://github.com/vorst4/TUE_5LSM0_g6.git\n",
            "   b78ab26..ef3ac4f  master -> master\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}